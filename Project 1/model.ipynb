{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,116,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,116,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,124,737</span> (4.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,124,737\u001b[0m (4.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,124,737</span> (4.29 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,124,737\u001b[0m (4.29 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 1.1666 - mse: 3.8188 - val_loss: 0.7592 - val_mse: 1.8338\n",
      "Epoch 2/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7952 - mse: 1.9416 - val_loss: 0.7848 - val_mse: 1.7718\n",
      "Epoch 3/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7663 - mse: 1.8708 - val_loss: 0.7368 - val_mse: 1.6945\n",
      "Epoch 4/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7461 - mse: 1.7548 - val_loss: 0.7550 - val_mse: 1.7251\n",
      "Epoch 5/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7446 - mse: 1.7910 - val_loss: 0.8743 - val_mse: 2.1252\n",
      "Epoch 6/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7475 - mse: 1.7747 - val_loss: 0.7332 - val_mse: 1.6696\n",
      "Epoch 7/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7402 - mse: 1.7820 - val_loss: 0.7641 - val_mse: 1.7836\n",
      "Epoch 8/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7337 - mse: 1.7770 - val_loss: 0.7650 - val_mse: 1.7648\n",
      "Epoch 9/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7378 - mse: 1.8721 - val_loss: 0.7510 - val_mse: 1.7018\n",
      "Epoch 10/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7240 - mse: 1.6889 - val_loss: 0.7251 - val_mse: 1.6737\n",
      "Epoch 11/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7192 - mse: 1.7335 - val_loss: 0.7937 - val_mse: 2.0622\n",
      "Epoch 12/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7146 - mse: 1.7048 - val_loss: 0.7680 - val_mse: 1.8621\n",
      "Epoch 13/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7122 - mse: 1.7885 - val_loss: 0.7554 - val_mse: 1.7884\n",
      "Epoch 14/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7082 - mse: 1.7796 - val_loss: 0.7393 - val_mse: 1.7623\n",
      "Epoch 15/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7117 - mse: 1.8210 - val_loss: 0.7210 - val_mse: 1.7110\n",
      "Epoch 16/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.7117 - mse: 1.7370 - val_loss: 0.7394 - val_mse: 1.6742\n",
      "Epoch 17/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.7051 - mse: 1.7605 - val_loss: 0.7276 - val_mse: 1.6412\n",
      "Epoch 18/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7118 - mse: 1.7343 - val_loss: 0.7418 - val_mse: 1.7865\n",
      "Epoch 19/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6982 - mse: 1.7130 - val_loss: 0.7294 - val_mse: 1.6859\n",
      "Epoch 20/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7018 - mse: 1.7084 - val_loss: 0.7267 - val_mse: 1.7470\n",
      "Epoch 21/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.6972 - mse: 1.7317 - val_loss: 0.7485 - val_mse: 1.6808\n",
      "Epoch 22/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7007 - mse: 1.6911 - val_loss: 0.7315 - val_mse: 1.7588\n",
      "Epoch 23/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7021 - mse: 1.7965 - val_loss: 0.7281 - val_mse: 1.7310\n",
      "Epoch 24/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7002 - mse: 1.7721 - val_loss: 0.7277 - val_mse: 1.7215\n",
      "Epoch 25/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6946 - mse: 1.7464 - val_loss: 0.7376 - val_mse: 1.7368\n",
      "Epoch 26/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.7006 - mse: 1.6777 - val_loss: 0.7258 - val_mse: 1.6983\n",
      "Epoch 27/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6966 - mse: 1.6672 - val_loss: 0.7629 - val_mse: 1.8152\n",
      "Epoch 28/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6972 - mse: 1.7456 - val_loss: 0.7346 - val_mse: 1.6845\n",
      "Epoch 29/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6896 - mse: 1.6580 - val_loss: 0.7314 - val_mse: 1.7236\n",
      "Epoch 30/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6889 - mse: 1.6435 - val_loss: 0.7447 - val_mse: 1.6489\n",
      "Epoch 31/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6888 - mse: 1.7241 - val_loss: 0.7746 - val_mse: 1.8199\n",
      "Epoch 32/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6918 - mse: 1.6437 - val_loss: 0.7464 - val_mse: 1.6444\n",
      "Epoch 33/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6971 - mse: 1.6777 - val_loss: 0.7301 - val_mse: 1.7143\n",
      "Epoch 34/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6956 - mse: 1.6666 - val_loss: 0.7343 - val_mse: 1.7350\n",
      "Epoch 35/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6971 - mse: 1.7658 - val_loss: 0.7306 - val_mse: 1.6792\n",
      "Epoch 36/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6955 - mse: 1.7034 - val_loss: 0.7622 - val_mse: 1.7872\n",
      "Epoch 37/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6957 - mse: 1.6862 - val_loss: 0.7221 - val_mse: 1.7048\n",
      "Epoch 38/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6901 - mse: 1.6364 - val_loss: 0.7449 - val_mse: 1.6539\n",
      "Epoch 39/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.6944 - mse: 1.7635 - val_loss: 0.7382 - val_mse: 1.6319\n",
      "Epoch 40/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6859 - mse: 1.6553 - val_loss: 0.7214 - val_mse: 1.7114\n",
      "Epoch 41/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6917 - mse: 1.7557 - val_loss: 0.7299 - val_mse: 1.7617\n",
      "Epoch 42/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6910 - mse: 1.7059 - val_loss: 0.7286 - val_mse: 1.6929\n",
      "Epoch 43/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6855 - mse: 1.6493 - val_loss: 0.7434 - val_mse: 1.6813\n",
      "Epoch 44/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6862 - mse: 1.6488 - val_loss: 0.7497 - val_mse: 1.7620\n",
      "Epoch 45/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6923 - mse: 1.7097 - val_loss: 0.7225 - val_mse: 1.7044\n",
      "Epoch 46/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6918 - mse: 1.7634 - val_loss: 0.7228 - val_mse: 1.7249\n",
      "Epoch 47/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6837 - mse: 1.6801 - val_loss: 0.7288 - val_mse: 1.7281\n",
      "Epoch 48/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6798 - mse: 1.6510 - val_loss: 0.7230 - val_mse: 1.7213\n",
      "Epoch 49/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6848 - mse: 1.6366 - val_loss: 0.7232 - val_mse: 1.7078\n",
      "Epoch 50/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6910 - mse: 1.6733 - val_loss: 0.7368 - val_mse: 1.6999\n",
      "Epoch 51/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6839 - mse: 1.6464 - val_loss: 0.7331 - val_mse: 1.7104\n",
      "Epoch 52/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6817 - mse: 1.6168 - val_loss: 0.7229 - val_mse: 1.7125\n",
      "Epoch 53/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6926 - mse: 1.7775 - val_loss: 0.7910 - val_mse: 1.6435\n",
      "Epoch 54/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6892 - mse: 1.7203 - val_loss: 0.7321 - val_mse: 1.7156\n",
      "Epoch 55/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6864 - mse: 1.7029 - val_loss: 0.7396 - val_mse: 1.7793\n",
      "Epoch 56/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6876 - mse: 1.7396 - val_loss: 0.7273 - val_mse: 1.7099\n",
      "Epoch 57/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6839 - mse: 1.6648 - val_loss: 0.7415 - val_mse: 1.7764\n",
      "Epoch 58/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6842 - mse: 1.6729 - val_loss: 0.7313 - val_mse: 1.7307\n",
      "Epoch 59/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6819 - mse: 1.6561 - val_loss: 0.7246 - val_mse: 1.7224\n",
      "Epoch 60/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6864 - mse: 1.6319 - val_loss: 0.7343 - val_mse: 1.7756\n",
      "Epoch 61/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6824 - mse: 1.6959 - val_loss: 0.7235 - val_mse: 1.7124\n",
      "Epoch 62/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6859 - mse: 1.7320 - val_loss: 0.7246 - val_mse: 1.6953\n",
      "Epoch 63/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6817 - mse: 1.6372 - val_loss: 0.7385 - val_mse: 1.7441\n",
      "Epoch 64/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6837 - mse: 1.6808 - val_loss: 0.7487 - val_mse: 1.6442\n",
      "Epoch 65/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.6866 - mse: 1.6738 - val_loss: 0.7357 - val_mse: 1.6849\n",
      "Epoch 66/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.6799 - mse: 1.6514 - val_loss: 0.7237 - val_mse: 1.7013\n",
      "Epoch 67/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6814 - mse: 1.6532 - val_loss: 0.7504 - val_mse: 1.6690\n",
      "Epoch 68/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6854 - mse: 1.6758 - val_loss: 0.7308 - val_mse: 1.6909\n",
      "Epoch 69/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6819 - mse: 1.6503 - val_loss: 0.7266 - val_mse: 1.6934\n",
      "Epoch 70/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6755 - mse: 1.6678 - val_loss: 0.7357 - val_mse: 1.7273\n",
      "Epoch 71/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6825 - mse: 1.7052 - val_loss: 0.7253 - val_mse: 1.6943\n",
      "Epoch 72/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6888 - mse: 1.6788 - val_loss: 0.7262 - val_mse: 1.7012\n",
      "Epoch 73/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6761 - mse: 1.6081 - val_loss: 0.7544 - val_mse: 1.7852\n",
      "Epoch 74/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6822 - mse: 1.6580 - val_loss: 0.7237 - val_mse: 1.6880\n",
      "Epoch 75/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6828 - mse: 1.6399 - val_loss: 0.7221 - val_mse: 1.7080\n",
      "Epoch 76/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6800 - mse: 1.6431 - val_loss: 0.7231 - val_mse: 1.6936\n",
      "Epoch 77/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6783 - mse: 1.6153 - val_loss: 0.7288 - val_mse: 1.7121\n",
      "Epoch 78/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6805 - mse: 1.6702 - val_loss: 0.7307 - val_mse: 1.7261\n",
      "Epoch 79/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6841 - mse: 1.6396 - val_loss: 0.7289 - val_mse: 1.7681\n",
      "Epoch 80/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6805 - mse: 1.6725 - val_loss: 0.7294 - val_mse: 1.6947\n",
      "Epoch 81/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6798 - mse: 1.6522 - val_loss: 0.7332 - val_mse: 1.7544\n",
      "Epoch 82/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6886 - mse: 1.6932 - val_loss: 0.7354 - val_mse: 1.7502\n",
      "Epoch 83/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6820 - mse: 1.6702 - val_loss: 0.7242 - val_mse: 1.7084\n",
      "Epoch 84/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6829 - mse: 1.6846 - val_loss: 0.7339 - val_mse: 1.6886\n",
      "Epoch 85/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6747 - mse: 1.6151 - val_loss: 0.7229 - val_mse: 1.6897\n",
      "Epoch 86/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6831 - mse: 1.6933 - val_loss: 0.7270 - val_mse: 1.7123\n",
      "Epoch 87/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6861 - mse: 1.7032 - val_loss: 0.7288 - val_mse: 1.6721\n",
      "Epoch 88/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.6748 - mse: 1.5913 - val_loss: 0.7267 - val_mse: 1.6969\n",
      "Epoch 89/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6802 - mse: 1.6610 - val_loss: 0.7598 - val_mse: 1.8109\n",
      "Epoch 90/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6842 - mse: 1.7242 - val_loss: 0.7492 - val_mse: 1.7952\n",
      "Epoch 91/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6828 - mse: 1.7032 - val_loss: 0.7465 - val_mse: 1.7616\n",
      "Epoch 92/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6839 - mse: 1.7583 - val_loss: 0.7242 - val_mse: 1.7169\n",
      "Epoch 93/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6808 - mse: 1.6628 - val_loss: 0.7277 - val_mse: 1.6781\n",
      "Epoch 94/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6795 - mse: 1.6601 - val_loss: 0.7335 - val_mse: 1.6737\n",
      "Epoch 95/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6820 - mse: 1.6806 - val_loss: 0.7268 - val_mse: 1.6736\n",
      "Epoch 96/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6738 - mse: 1.5901 - val_loss: 0.7491 - val_mse: 1.6617\n",
      "Epoch 97/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6734 - mse: 1.6258 - val_loss: 0.7280 - val_mse: 1.7402\n",
      "Epoch 98/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6770 - mse: 1.6178 - val_loss: 0.7326 - val_mse: 1.6726\n",
      "Epoch 99/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.6736 - mse: 1.6048 - val_loss: 0.7401 - val_mse: 1.6565\n",
      "Epoch 100/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.6751 - mse: 1.6052 - val_loss: 0.7255 - val_mse: 1.7379\n",
      "Epoch 101/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.6772 - mse: 1.6107 - val_loss: 0.7280 - val_mse: 1.6803\n",
      "Epoch 102/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.6784 - mse: 1.6693 - val_loss: 0.7270 - val_mse: 1.7381\n",
      "Epoch 103/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.6826 - mse: 1.7115 - val_loss: 0.7365 - val_mse: 1.6969\n",
      "Epoch 104/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.6768 - mse: 1.6704 - val_loss: 0.7275 - val_mse: 1.7022\n",
      "Epoch 105/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.6808 - mse: 1.7089 - val_loss: 0.7241 - val_mse: 1.6925\n",
      "Epoch 106/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - loss: 0.6772 - mse: 1.6446 - val_loss: 0.7356 - val_mse: 1.7751\n",
      "Epoch 107/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.6777 - mse: 1.6259 - val_loss: 0.7235 - val_mse: 1.7065\n",
      "Epoch 108/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6795 - mse: 1.6429 - val_loss: 0.7230 - val_mse: 1.7055\n",
      "Epoch 109/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6729 - mse: 1.6329 - val_loss: 0.7244 - val_mse: 1.7135\n",
      "Epoch 110/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6795 - mse: 1.6653 - val_loss: 0.7294 - val_mse: 1.7446\n",
      "Epoch 111/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6777 - mse: 1.6590 - val_loss: 0.7237 - val_mse: 1.7298\n",
      "Epoch 112/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6756 - mse: 1.6372 - val_loss: 0.7233 - val_mse: 1.7058\n",
      "Epoch 113/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.6771 - mse: 1.6389 - val_loss: 0.7449 - val_mse: 1.7719\n",
      "Epoch 114/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6760 - mse: 1.6616 - val_loss: 0.7332 - val_mse: 1.7011\n",
      "Epoch 115/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6741 - mse: 1.6589 - val_loss: 0.7378 - val_mse: 1.7911\n",
      "Epoch 116/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6725 - mse: 1.6692 - val_loss: 0.7366 - val_mse: 1.7619\n",
      "Epoch 117/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6742 - mse: 1.6578 - val_loss: 0.7251 - val_mse: 1.6923\n",
      "Epoch 118/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6721 - mse: 1.6293 - val_loss: 0.7397 - val_mse: 1.7489\n",
      "Epoch 119/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6761 - mse: 1.5916 - val_loss: 0.7630 - val_mse: 1.7843\n",
      "Epoch 120/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6768 - mse: 1.6276 - val_loss: 0.7291 - val_mse: 1.6769\n",
      "Epoch 121/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6769 - mse: 1.6979 - val_loss: 0.7338 - val_mse: 1.7531\n",
      "Epoch 122/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6779 - mse: 1.6677 - val_loss: 0.7381 - val_mse: 1.7490\n",
      "Epoch 123/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6774 - mse: 1.6943 - val_loss: 0.7246 - val_mse: 1.6829\n",
      "Epoch 124/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6725 - mse: 1.6408 - val_loss: 0.7274 - val_mse: 1.7433\n",
      "Epoch 125/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6804 - mse: 1.6438 - val_loss: 0.7386 - val_mse: 1.6796\n",
      "Epoch 126/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6717 - mse: 1.6306 - val_loss: 0.7443 - val_mse: 1.6647\n",
      "Epoch 127/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6757 - mse: 1.6091 - val_loss: 0.7309 - val_mse: 1.7595\n",
      "Epoch 128/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6779 - mse: 1.6727 - val_loss: 0.7345 - val_mse: 1.7490\n",
      "Epoch 129/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6757 - mse: 1.6115 - val_loss: 0.7248 - val_mse: 1.6889\n",
      "Epoch 130/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6760 - mse: 1.6486 - val_loss: 0.7241 - val_mse: 1.7248\n",
      "Epoch 131/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6797 - mse: 1.6753 - val_loss: 0.7503 - val_mse: 1.6562\n",
      "Epoch 132/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - loss: 0.6777 - mse: 1.6344 - val_loss: 0.7242 - val_mse: 1.7214\n",
      "Epoch 133/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6769 - mse: 1.6646 - val_loss: 0.7274 - val_mse: 1.7213\n",
      "Epoch 134/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6728 - mse: 1.6296 - val_loss: 0.7360 - val_mse: 1.7712\n",
      "Epoch 135/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.6779 - mse: 1.6541 - val_loss: 0.7332 - val_mse: 1.6957\n",
      "Epoch 136/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6792 - mse: 1.6573 - val_loss: 0.7482 - val_mse: 1.7785\n",
      "Epoch 137/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6769 - mse: 1.6780 - val_loss: 0.7306 - val_mse: 1.6925\n",
      "Epoch 138/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6749 - mse: 1.6511 - val_loss: 0.7333 - val_mse: 1.7057\n",
      "Epoch 139/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6721 - mse: 1.6070 - val_loss: 0.7357 - val_mse: 1.6582\n",
      "Epoch 140/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.6720 - mse: 1.5832 - val_loss: 0.7329 - val_mse: 1.6816\n",
      "Epoch 141/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6754 - mse: 1.6617 - val_loss: 0.7252 - val_mse: 1.6879\n",
      "Epoch 142/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6714 - mse: 1.6271 - val_loss: 0.7297 - val_mse: 1.6788\n",
      "Epoch 143/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6725 - mse: 1.6462 - val_loss: 0.7368 - val_mse: 1.6723\n",
      "Epoch 144/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6803 - mse: 1.6722 - val_loss: 0.7311 - val_mse: 1.7066\n",
      "Epoch 145/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6739 - mse: 1.6476 - val_loss: 0.7577 - val_mse: 1.8188\n",
      "Epoch 146/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6795 - mse: 1.6432 - val_loss: 0.7316 - val_mse: 1.7469\n",
      "Epoch 147/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6823 - mse: 1.6780 - val_loss: 0.7332 - val_mse: 1.6971\n",
      "Epoch 148/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6765 - mse: 1.6344 - val_loss: 0.7231 - val_mse: 1.7185\n",
      "Epoch 149/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6727 - mse: 1.6498 - val_loss: 0.7242 - val_mse: 1.6924\n",
      "Epoch 150/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6813 - mse: 1.6892 - val_loss: 0.7564 - val_mse: 1.6696\n",
      "Epoch 151/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6726 - mse: 1.6569 - val_loss: 0.7233 - val_mse: 1.7125\n",
      "Epoch 152/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6669 - mse: 1.5753 - val_loss: 0.7316 - val_mse: 1.6821\n",
      "Epoch 153/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6728 - mse: 1.6433 - val_loss: 0.7235 - val_mse: 1.7161\n",
      "Epoch 154/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6755 - mse: 1.6670 - val_loss: 0.7339 - val_mse: 1.6817\n",
      "Epoch 155/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6705 - mse: 1.6431 - val_loss: 0.7281 - val_mse: 1.7544\n",
      "Epoch 156/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6794 - mse: 1.6846 - val_loss: 0.7385 - val_mse: 1.7841\n",
      "Epoch 157/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6753 - mse: 1.7124 - val_loss: 0.7254 - val_mse: 1.7129\n",
      "Epoch 158/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6737 - mse: 1.6367 - val_loss: 0.7239 - val_mse: 1.7124\n",
      "Epoch 159/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6785 - mse: 1.6579 - val_loss: 0.7373 - val_mse: 1.6919\n",
      "Epoch 160/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6732 - mse: 1.6499 - val_loss: 0.7250 - val_mse: 1.7008\n",
      "Epoch 161/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6745 - mse: 1.6358 - val_loss: 0.7329 - val_mse: 1.6876\n",
      "Epoch 162/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6770 - mse: 1.6351 - val_loss: 0.7351 - val_mse: 1.7601\n",
      "Epoch 163/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6721 - mse: 1.6512 - val_loss: 0.7436 - val_mse: 1.6720\n",
      "Epoch 164/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6754 - mse: 1.7263 - val_loss: 0.7279 - val_mse: 1.6939\n",
      "Epoch 165/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6739 - mse: 1.6789 - val_loss: 0.7390 - val_mse: 1.6837\n",
      "Epoch 166/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6757 - mse: 1.6558 - val_loss: 0.7265 - val_mse: 1.7421\n",
      "Epoch 167/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6718 - mse: 1.6314 - val_loss: 0.7239 - val_mse: 1.7384\n",
      "Epoch 168/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6687 - mse: 1.5738 - val_loss: 0.7260 - val_mse: 1.7564\n",
      "Epoch 169/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6679 - mse: 1.6047 - val_loss: 0.7338 - val_mse: 1.7146\n",
      "Epoch 170/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6807 - mse: 1.6955 - val_loss: 0.7829 - val_mse: 1.8983\n",
      "Epoch 171/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6799 - mse: 1.6997 - val_loss: 0.7244 - val_mse: 1.7299\n",
      "Epoch 172/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6778 - mse: 1.6361 - val_loss: 0.7270 - val_mse: 1.7187\n",
      "Epoch 173/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6739 - mse: 1.6316 - val_loss: 0.7359 - val_mse: 1.7514\n",
      "Epoch 174/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6784 - mse: 1.6434 - val_loss: 0.7245 - val_mse: 1.7205\n",
      "Epoch 175/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6710 - mse: 1.6280 - val_loss: 0.7269 - val_mse: 1.6901\n",
      "Epoch 176/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6716 - mse: 1.6679 - val_loss: 0.7309 - val_mse: 1.7419\n",
      "Epoch 177/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6770 - mse: 1.6708 - val_loss: 0.7432 - val_mse: 1.7798\n",
      "Epoch 178/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6753 - mse: 1.6675 - val_loss: 0.7227 - val_mse: 1.7328\n",
      "Epoch 179/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6732 - mse: 1.6455 - val_loss: 0.7265 - val_mse: 1.7206\n",
      "Epoch 180/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6746 - mse: 1.6535 - val_loss: 0.7345 - val_mse: 1.7172\n",
      "Epoch 181/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6756 - mse: 1.6356 - val_loss: 0.7297 - val_mse: 1.7590\n",
      "Epoch 182/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6707 - mse: 1.6051 - val_loss: 0.7305 - val_mse: 1.7422\n",
      "Epoch 183/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6713 - mse: 1.6557 - val_loss: 0.7263 - val_mse: 1.7150\n",
      "Epoch 184/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6763 - mse: 1.6782 - val_loss: 0.7263 - val_mse: 1.7422\n",
      "Epoch 185/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6715 - mse: 1.6180 - val_loss: 0.7347 - val_mse: 1.7631\n",
      "Epoch 186/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6718 - mse: 1.6659 - val_loss: 0.7235 - val_mse: 1.7238\n",
      "Epoch 187/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6713 - mse: 1.5876 - val_loss: 0.7329 - val_mse: 1.7451\n",
      "Epoch 188/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6756 - mse: 1.6309 - val_loss: 0.7283 - val_mse: 1.7511\n",
      "Epoch 189/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6770 - mse: 1.6483 - val_loss: 0.7407 - val_mse: 1.7772\n",
      "Epoch 190/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6790 - mse: 1.6572 - val_loss: 0.7233 - val_mse: 1.7289\n",
      "Epoch 191/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6710 - mse: 1.6977 - val_loss: 0.7340 - val_mse: 1.6950\n",
      "Epoch 192/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6742 - mse: 1.6615 - val_loss: 0.7320 - val_mse: 1.6876\n",
      "Epoch 193/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6717 - mse: 1.6458 - val_loss: 0.7409 - val_mse: 1.7396\n",
      "Epoch 194/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6716 - mse: 1.6223 - val_loss: 0.7439 - val_mse: 1.6687\n",
      "Epoch 195/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6694 - mse: 1.6255 - val_loss: 0.7261 - val_mse: 1.7050\n",
      "Epoch 196/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6772 - mse: 1.6407 - val_loss: 0.7256 - val_mse: 1.7111\n",
      "Epoch 197/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6754 - mse: 1.6586 - val_loss: 0.7266 - val_mse: 1.7207\n",
      "Epoch 198/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6684 - mse: 1.6309 - val_loss: 0.7244 - val_mse: 1.7021\n",
      "Epoch 199/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6800 - mse: 1.6558 - val_loss: 0.7460 - val_mse: 1.7066\n",
      "Epoch 200/200\n",
      "\u001b[1m1775/1775\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - loss: 0.6681 - mse: 1.6214 - val_loss: 0.7323 - val_mse: 1.6893\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 589us/step - loss: 0.7311 - mse: 1.6782\n",
      "Loss en el conjunto de prueba: 0.7378088235855103, MSE en el conjunto de prueba: 1.724100112915039\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Cargar el archivo\n",
    "file_path = 'attachments/Conjunto_servidores_p_blicos_20240819.csv'\n",
    "df = pd.read_csv(file_path, dtype={'Columna_8': str, 'Columna_9': str}, low_memory=False)\n",
    "\n",
    "df = df[['Meses de Experiencia Público', 'Meses de Experiencia Privado',\n",
    "         'Nivel Educativo', 'Tipo de Nombramiento', 'Nivel Jerarquico Empleo',\n",
    "         'Dependencia Empleo Actual', 'Asignación Básica Salarial']]\n",
    "\n",
    "# Convertir las columnas numéricas y rellenar nulos\n",
    "df.loc[:, 'Meses de Experiencia Público'] = pd.to_numeric(df['Meses de Experiencia Público'], errors='coerce').fillna(0)\n",
    "df.loc[:, 'Meses de Experiencia Privado'] = pd.to_numeric(df['Meses de Experiencia Privado'], errors='coerce').fillna(0)\n",
    "\n",
    "df = df.dropna(subset=['Nivel Educativo', 'Nivel Jerarquico Empleo', 'Dependencia Empleo Actual', 'Asignación Básica Salarial'])\n",
    "\n",
    "# Convertir la columna 'Asignación Básica Salarial' a valores numéricos y escalarla a millones\n",
    "df['Asignación Básica Salarial'] = df['Asignación Básica Salarial'].replace({'$': '', ',': ''}, regex=True).astype(float)\n",
    "df['Asignación Básica Salarial'] = df['Asignación Básica Salarial'] / 1_000_000\n",
    "\n",
    "# One-Hot Encoding para las columnas categóricas\n",
    "df = pd.get_dummies(df, columns=['Nivel Educativo', 'Tipo de Nombramiento', 'Nivel Jerarquico Empleo', 'Dependencia Empleo Actual'])\n",
    "\n",
    "# Definir características (X) y etiqueta (y)\n",
    "X = df.drop(columns=['Asignación Básica Salarial'])\n",
    "y = df['Asignación Básica Salarial']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir todas las columnas de X_train y X_test a tipo int\n",
    "X_train = X_train.astype(int)\n",
    "X_test = X_test.astype(int)\n",
    "\n",
    "# Definir el modelo de regresión lineal\n",
    "model = Sequential()\n",
    "\n",
    "# Agregar capas Dense con funciones de activación lineales\n",
    "model.add(Dense(128, input_shape=(X_train.shape[1],), activation='linear'))  # Capa oculta\n",
    "model.add(Dense(64, activation='linear'))  # Otra capa oculta\n",
    "model.add(Dense(1, activation='linear'))  # Capa de salida\n",
    "\n",
    "# Compilar el modelo con diferentes hiperparámetros\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mae', metrics=[\"mse\"])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=64, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_mse = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Loss en el conjunto de prueba: {test_loss}, MSE en el conjunto de prueba: {test_mse}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
