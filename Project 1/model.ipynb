{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aleja\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,232,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m2,232,832\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,274,049</span> (8.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,274,049\u001b[0m (8.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,274,049</span> (8.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,274,049\u001b[0m (8.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 15ms/step - loss: 10.7812 - mae: 1.7142 - val_loss: 1.7106 - val_mae: 0.8757\n",
      "Epoch 2/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.7745 - mae: 0.8700 - val_loss: 1.8094 - val_mae: 0.9678\n",
      "Epoch 3/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.7705 - mae: 0.8576 - val_loss: 1.6786 - val_mae: 0.8462\n",
      "Epoch 4/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.7003 - mae: 0.8577 - val_loss: 1.5619 - val_mae: 0.8064\n",
      "Epoch 5/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.6339 - mae: 0.8358 - val_loss: 1.8879 - val_mae: 0.9467\n",
      "Epoch 6/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.6297 - mae: 0.8359 - val_loss: 1.5809 - val_mae: 0.8618\n",
      "Epoch 7/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.6018 - mae: 0.8185 - val_loss: 1.5468 - val_mae: 0.7969\n",
      "Epoch 8/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.5592 - mae: 0.8132 - val_loss: 2.7209 - val_mae: 1.1170\n",
      "Epoch 9/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.6815 - mae: 0.8180 - val_loss: 1.5789 - val_mae: 0.8447\n",
      "Epoch 10/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.5515 - mae: 0.8018 - val_loss: 1.5559 - val_mae: 0.8245\n",
      "Epoch 11/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.5628 - mae: 0.8052 - val_loss: 1.5697 - val_mae: 0.8434\n",
      "Epoch 12/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.6582 - mae: 0.8019 - val_loss: 1.5376 - val_mae: 0.8319\n",
      "Epoch 13/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.5216 - mae: 0.7908 - val_loss: 1.5171 - val_mae: 0.8240\n",
      "Epoch 14/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.5087 - mae: 0.7934 - val_loss: 1.5551 - val_mae: 0.8119\n",
      "Epoch 15/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.4902 - mae: 0.7946 - val_loss: 1.8703 - val_mae: 1.0070\n",
      "Epoch 16/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.5011 - mae: 0.7902 - val_loss: 1.6216 - val_mae: 0.8870\n",
      "Epoch 17/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.5029 - mae: 0.7895 - val_loss: 1.6380 - val_mae: 0.8126\n",
      "Epoch 18/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4797 - mae: 0.7804 - val_loss: 1.5416 - val_mae: 0.8298\n",
      "Epoch 19/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4433 - mae: 0.7808 - val_loss: 1.5327 - val_mae: 0.7937\n",
      "Epoch 20/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4851 - mae: 0.7790 - val_loss: 1.5525 - val_mae: 0.8049\n",
      "Epoch 21/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.4545 - mae: 0.7781 - val_loss: 1.5296 - val_mae: 0.7906\n",
      "Epoch 22/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.4619 - mae: 0.7817 - val_loss: 1.5618 - val_mae: 0.7988\n",
      "Epoch 23/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4387 - mae: 0.7771 - val_loss: 1.5373 - val_mae: 0.8344\n",
      "Epoch 24/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4763 - mae: 0.7832 - val_loss: 1.5387 - val_mae: 0.8180\n",
      "Epoch 25/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.5100 - mae: 0.7813 - val_loss: 1.5631 - val_mae: 0.8487\n",
      "Epoch 26/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.5034 - mae: 0.7829 - val_loss: 1.5259 - val_mae: 0.8214\n",
      "Epoch 27/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4785 - mae: 0.7838 - val_loss: 1.5649 - val_mae: 0.8210\n",
      "Epoch 28/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4921 - mae: 0.7808 - val_loss: 1.7603 - val_mae: 0.9535\n",
      "Epoch 29/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.5212 - mae: 0.7835 - val_loss: 1.5892 - val_mae: 0.8345\n",
      "Epoch 30/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.5052 - mae: 0.7806 - val_loss: 1.5643 - val_mae: 0.8089\n",
      "Epoch 31/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.4117 - mae: 0.7717 - val_loss: 1.5683 - val_mae: 0.8479\n",
      "Epoch 32/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4712 - mae: 0.7779 - val_loss: 1.7006 - val_mae: 0.8624\n",
      "Epoch 33/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4638 - mae: 0.7746 - val_loss: 1.5483 - val_mae: 0.8185\n",
      "Epoch 34/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4100 - mae: 0.7704 - val_loss: 1.6042 - val_mae: 0.8256\n",
      "Epoch 35/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4787 - mae: 0.7815 - val_loss: 1.5643 - val_mae: 0.8260\n",
      "Epoch 36/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4565 - mae: 0.7699 - val_loss: 1.5412 - val_mae: 0.8296\n",
      "Epoch 37/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4092 - mae: 0.7704 - val_loss: 1.5744 - val_mae: 0.8507\n",
      "Epoch 38/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4448 - mae: 0.7729 - val_loss: 1.5294 - val_mae: 0.8068\n",
      "Epoch 39/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4359 - mae: 0.7736 - val_loss: 1.6318 - val_mae: 0.8855\n",
      "Epoch 40/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4590 - mae: 0.7650 - val_loss: 1.9331 - val_mae: 0.9703\n",
      "Epoch 41/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 1.4197 - mae: 0.7702 - val_loss: 1.5279 - val_mae: 0.8094\n",
      "Epoch 42/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.4596 - mae: 0.7731 - val_loss: 1.5505 - val_mae: 0.8131\n",
      "Epoch 43/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 1.4099 - mae: 0.7687 - val_loss: 1.5496 - val_mae: 0.7864\n",
      "Epoch 44/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 1.4545 - mae: 0.7715 - val_loss: 1.6173 - val_mae: 0.8768\n",
      "Epoch 45/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.4624 - mae: 0.7755 - val_loss: 1.5299 - val_mae: 0.8116\n",
      "Epoch 46/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4493 - mae: 0.7756 - val_loss: 1.5378 - val_mae: 0.8101\n",
      "Epoch 47/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4198 - mae: 0.7724 - val_loss: 1.5541 - val_mae: 0.8264\n",
      "Epoch 48/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4196 - mae: 0.7668 - val_loss: 1.5326 - val_mae: 0.7991\n",
      "Epoch 49/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4460 - mae: 0.7706 - val_loss: 1.5290 - val_mae: 0.8004\n",
      "Epoch 50/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4736 - mae: 0.7741 - val_loss: 1.5434 - val_mae: 0.8196\n",
      "Epoch 51/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4364 - mae: 0.7645 - val_loss: 1.6194 - val_mae: 0.8563\n",
      "Epoch 52/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4327 - mae: 0.7797 - val_loss: 1.5315 - val_mae: 0.8053\n",
      "Epoch 53/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.4195 - mae: 0.7675 - val_loss: 1.6216 - val_mae: 0.8676\n",
      "Epoch 54/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 1.4111 - mae: 0.7631 - val_loss: 1.5295 - val_mae: 0.8051\n",
      "Epoch 55/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 1.4648 - mae: 0.7737 - val_loss: 1.7822 - val_mae: 0.9578\n",
      "Epoch 56/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - loss: 1.4335 - mae: 0.7656 - val_loss: 1.5348 - val_mae: 0.8028\n",
      "Epoch 57/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4259 - mae: 0.7648 - val_loss: 1.5673 - val_mae: 0.8006\n",
      "Epoch 58/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4295 - mae: 0.7747 - val_loss: 1.5464 - val_mae: 0.7965\n",
      "Epoch 59/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.4217 - mae: 0.7611 - val_loss: 1.6504 - val_mae: 0.8813\n",
      "Epoch 60/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4398 - mae: 0.7736 - val_loss: 1.5842 - val_mae: 0.8549\n",
      "Epoch 61/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4257 - mae: 0.7667 - val_loss: 1.5921 - val_mae: 0.7991\n",
      "Epoch 62/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4562 - mae: 0.7709 - val_loss: 1.5276 - val_mae: 0.8108\n",
      "Epoch 63/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.4336 - mae: 0.7634 - val_loss: 1.5544 - val_mae: 0.8130\n",
      "Epoch 64/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - loss: 1.4086 - mae: 0.7633 - val_loss: 1.5280 - val_mae: 0.7932\n",
      "Epoch 65/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 13ms/step - loss: 1.3971 - mae: 0.7610 - val_loss: 1.5772 - val_mae: 0.8402\n",
      "Epoch 66/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.4021 - mae: 0.7675 - val_loss: 1.5609 - val_mae: 0.8221\n",
      "Epoch 67/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.4079 - mae: 0.7691 - val_loss: 1.5770 - val_mae: 0.8428\n",
      "Epoch 68/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - loss: 1.4278 - mae: 0.7677 - val_loss: 1.5725 - val_mae: 0.8382\n",
      "Epoch 69/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.4407 - mae: 0.7691 - val_loss: 1.5645 - val_mae: 0.8380\n",
      "Epoch 70/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4096 - mae: 0.7681 - val_loss: 1.6423 - val_mae: 0.8588\n",
      "Epoch 71/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4335 - mae: 0.7668 - val_loss: 1.7104 - val_mae: 0.9184\n",
      "Epoch 72/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.4351 - mae: 0.7668 - val_loss: 1.5931 - val_mae: 0.8554\n",
      "Epoch 73/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.4056 - mae: 0.7619 - val_loss: 1.5487 - val_mae: 0.8187\n",
      "Epoch 74/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.3695 - mae: 0.7553 - val_loss: 1.5575 - val_mae: 0.8333\n",
      "Epoch 75/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.4884 - mae: 0.7765 - val_loss: 1.6023 - val_mae: 0.8187\n",
      "Epoch 76/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.3989 - mae: 0.7616 - val_loss: 1.5600 - val_mae: 0.8114\n",
      "Epoch 77/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4393 - mae: 0.7621 - val_loss: 1.5303 - val_mae: 0.8036\n",
      "Epoch 78/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4276 - mae: 0.7642 - val_loss: 1.5783 - val_mae: 0.7851\n",
      "Epoch 79/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4069 - mae: 0.7638 - val_loss: 1.6969 - val_mae: 0.8809\n",
      "Epoch 80/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4079 - mae: 0.7654 - val_loss: 1.5344 - val_mae: 0.8134\n",
      "Epoch 81/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.3895 - mae: 0.7597 - val_loss: 1.5468 - val_mae: 0.8127\n",
      "Epoch 82/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.4219 - mae: 0.7624 - val_loss: 1.5455 - val_mae: 0.8182\n",
      "Epoch 83/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.4087 - mae: 0.7605 - val_loss: 1.5998 - val_mae: 0.8304\n",
      "Epoch 84/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4777 - mae: 0.7717 - val_loss: 1.6280 - val_mae: 0.8792\n",
      "Epoch 85/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4089 - mae: 0.7658 - val_loss: 1.5857 - val_mae: 0.8154\n",
      "Epoch 86/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4060 - mae: 0.7611 - val_loss: 1.5496 - val_mae: 0.8042\n",
      "Epoch 87/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4322 - mae: 0.7652 - val_loss: 1.5328 - val_mae: 0.8099\n",
      "Epoch 88/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.3609 - mae: 0.7497 - val_loss: 1.5603 - val_mae: 0.8173\n",
      "Epoch 89/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4044 - mae: 0.7634 - val_loss: 1.6703 - val_mae: 0.8644\n",
      "Epoch 90/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.4258 - mae: 0.7673 - val_loss: 1.5641 - val_mae: 0.8360\n",
      "Epoch 91/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.4196 - mae: 0.7598 - val_loss: 1.5622 - val_mae: 0.8131\n",
      "Epoch 92/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.4114 - mae: 0.7637 - val_loss: 1.6132 - val_mae: 0.8646\n",
      "Epoch 93/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4163 - mae: 0.7591 - val_loss: 1.5781 - val_mae: 0.8461\n",
      "Epoch 94/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.3519 - mae: 0.7491 - val_loss: 1.6035 - val_mae: 0.8443\n",
      "Epoch 95/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.4344 - mae: 0.7669 - val_loss: 1.5617 - val_mae: 0.8217\n",
      "Epoch 96/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.4249 - mae: 0.7686 - val_loss: 1.5830 - val_mae: 0.8185\n",
      "Epoch 97/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.3974 - mae: 0.7609 - val_loss: 1.5348 - val_mae: 0.8043\n",
      "Epoch 98/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - loss: 1.3855 - mae: 0.7585 - val_loss: 1.5283 - val_mae: 0.7961\n",
      "Epoch 99/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4244 - mae: 0.7644 - val_loss: 1.5467 - val_mae: 0.8196\n",
      "Epoch 100/100\n",
      "\u001b[1m888/888\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 14ms/step - loss: 1.4128 - mae: 0.7651 - val_loss: 1.5519 - val_mae: 0.8187\n",
      "\u001b[1m1110/1110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 990us/step - loss: 1.5436 - mae: 0.8129\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     65\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 66\u001b[0m train_mse \u001b[38;5;241m=\u001b[39m \u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmse\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     67\u001b[0m val_mse \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_mse\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Graficar la pérdida (loss) a lo largo de las épocas\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mse'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "\n",
    "# Cargar el archivo\n",
    "file_path = 'attachments/Conjunto_servidores_p_blicos_20240819.csv'\n",
    "df = pd.read_csv(file_path, dtype={'Columna_8': str, 'Columna_9': str}, low_memory=False)\n",
    "\n",
    "df = df[['Meses de Experiencia Público', 'Meses de Experiencia Privado',\n",
    "        'Nivel Educativo', 'Tipo de Nombramiento', 'Nivel Jerarquico Empleo',\n",
    "        'Dependencia Empleo Actual', 'Asignación Básica Salarial']]\n",
    "\n",
    "# Convertir las columnas numéricas y rellenar nulos\n",
    "df.loc[:, 'Meses de Experiencia Público'] = pd.to_numeric(df['Meses de Experiencia Público'], errors='coerce').fillna(0)\n",
    "df.loc[:, 'Meses de Experiencia Privado'] = pd.to_numeric(df['Meses de Experiencia Privado'], errors='coerce').fillna(0)\n",
    "\n",
    "df = df.dropna(subset=['Nivel Educativo', 'Nivel Jerarquico Empleo', 'Dependencia Empleo Actual', 'Asignación Básica Salarial'])\n",
    "\n",
    "# Convertir la columna 'Asignación Básica Salarial' a valores numéricos y escalarla a millones\n",
    "df['Asignación Básica Salarial'] = df['Asignación Básica Salarial'].replace({'$': '', ',': ''}, regex=True).astype(float)\n",
    "df['Asignación Básica Salarial'] = df['Asignación Básica Salarial'] / 1_000_000\n",
    "\n",
    "# One-Hot Encoding para las columnas categóricas\n",
    "df = pd.get_dummies(df, columns=['Nivel Educativo', 'Tipo de Nombramiento', 'Nivel Jerarquico Empleo', 'Dependencia Empleo Actual'])\n",
    "\n",
    "# Definir características (X) y etiqueta (y)\n",
    "X = df.drop(columns=['Asignación Básica Salarial'])\n",
    "y = df['Asignación Básica Salarial']\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir todas las columnas de X_train y X_test a tipo int\n",
    "X_train = X_train.astype(int)\n",
    "X_test = X_test.astype(int)\n",
    "\n",
    "# Definir el modelo de regresión lineal\n",
    "model = Sequential()\n",
    "\n",
    "# Agregar capas Dense con funciones de activación lineales\n",
    "model.add(Dense(256, input_shape=(X_train.shape[1],)))  # Capa oculta\n",
    "model.add(Dense(128))  # Capa oculta\n",
    "model.add(Dense(64)) # Otra capa oculta\n",
    "model.add(Dense(1))  # Capa de salida\n",
    "\n",
    "# Compilar el modelo con diferentes hiperparámetros\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005), loss='mse', metrics=[\"mae\"])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=128, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_loss, test_mse = model.evaluate(X_test, y_test)\n",
    "\n",
    "\n",
    "# Acceder a los valores de pérdida y mse del historial de entrenamiento\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_mse = history.history['mse']\n",
    "val_mse = history.history['val_mse']\n",
    "\n",
    "# Graficar la pérdida (loss) a lo largo de las épocas\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Pérdida de Entrenamiento')\n",
    "plt.plot(val_loss, label='Pérdida de Validación')\n",
    "plt.title('Pérdida durante el Entrenamiento y Validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida (MAE)')\n",
    "plt.legend()\n",
    "\n",
    "# Graficar el MSE a lo largo de las épocas\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_mse, label='MSE de Entrenamiento')\n",
    "plt.plot(val_mse, label='MSE de Validación')\n",
    "plt.title('MSE durante el Entrenamiento y Validación')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
