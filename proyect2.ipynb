{"nbformat": 4, "nbformat_minor": 0, "metadata": {}, "cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Phases (adjust according to the proposed methodology)\n### Dataset distribution\n"]}, {"cell_type": "code", "metadata": {}, "source": ["import torch\n", "import torch.nn as nn\n", "import torch.optim as optim\n", "from torch.utils.data import DataLoader\n", "import torchvision.models as models\n", "import torchvision.transforms as transforms\n", "import matplotlib.pyplot as plt\n", "from sklearn.metrics import classification_report, confusion_matrix\n", "import seaborn as sns\n", "import numpy as np\n", "import tensorflow_datasets as tfds\n", "\n", "# Descargar y preparar el dataset EuroSAT\n", "dataset, info = tfds.load('eurosat', with_info=True, as_supervised=True)\n", "train_dataset = dataset['train']\n", "num_classes = info.features['label'].num_classes\n", "class_names = info.features['label'].names\n", "print(f'N\u00famero de clases: {num_classes}')\n", "print(f'Clases: {class_names}')\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Baseline models (at least three architectures in PyTorch)\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Transformaciones de imagen\n", "transform = transforms.Compose([\n", "    transforms.ToPILImage(),\n", "    transforms.Resize((64, 64)),\n", "    transforms.ToTensor(),\n", "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n", "])\n", "\n", "# Preprocesar el dataset\n", "def preprocess(dataset, transform):\n", "    images = []\n", "    labels = []\n", "    for image, label in tfds.as_numpy(dataset):\n", "        image = transform(image)\n", "        images.append(image)\n", "        labels.append(label)\n", "    return torch.stack(images), torch.tensor(labels)\n", "\n", "# Dividir el dataset en entrenamiento, validaci\u00f3n y prueba\n", "train_size = int(0.8 * len(train_dataset))\n", "val_size = int(0.1 * len(train_dataset))\n", "train_data, train_labels = preprocess(train_dataset.take(train_size), transform)\n", "val_data, val_labels = preprocess(train_dataset.skip(train_size).take(val_size), transform)\n", "test_data, test_labels = preprocess(train_dataset.skip(train_size + val_size), transform)\n", "\n", "# Crear DataLoaders\n", "batch_size = 32\n", "train_loader = DataLoader(list(zip(train_data, train_labels)), batch_size=batch_size, shuffle=True)\n", "val_loader = DataLoader(list(zip(val_data, val_labels)), batch_size=batch_size)\n", "test_loader = DataLoader(list(zip(test_data, test_labels)), batch_size=batch_size)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Hyperparameter selection\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Funci\u00f3n para crear modelos base\n", "def create_model(model_name):\n", "    if model_name == 'resnet18':\n", "        model = models.resnet18(pretrained=True)\n", "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n", "    elif model_name == 'vgg16':\n", "        model = models.vgg16(pretrained=True)\n", "        model.classifier[6] = nn.Linear(4096, num_classes)\n", "    elif model_name == 'efficientnet_b0':\n", "        model = models.efficientnet_b0(pretrained=True)\n", "        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n", "    return model\n", "\n", "# Crear modelo y definir par\u00e1metros\n", "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n", "epochs = 10\n", "lr = 0.001\n", "criterion = nn.CrossEntropyLoss()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Model fine tuning\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Entrenamiento del modelo\n", "def train_model(model, train_loader, val_loader, epochs, lr):\n", "    optimizer = optim.Adam(model.parameters(), lr=lr)\n", "    train_losses, val_losses = [], []\n", "    for epoch in range(epochs):\n", "        model.train()\n", "        running_loss = 0.0\n", "        for images, labels in train_loader:\n", "            images, labels = images.to(device), labels.to(device)\n", "            optimizer.zero_grad()\n", "            outputs = model(images)\n", "            loss = criterion(outputs, labels)\n", "            loss.backward()\n", "            optimizer.step()\n", "            running_loss += loss.item()\n", "        train_losses.append(running_loss / len(train_loader))\n", "        \n", "        model.eval()\n", "        val_loss = 0.0\n", "        with torch.no_grad():\n", "            for images, labels in val_loader:\n", "                images, labels = images.to(device), labels.to(device)\n", "                outputs = model(images)\n", "                loss = criterion(outputs, labels)\n", "                val_loss += loss.item()\n", "        val_losses.append(val_loss / len(val_loader))\n", "        print(f'Epoch {epoch + 1}/{epochs}, Training Loss: {train_losses[-1]}, Validation Loss: {val_losses[-1]}')\n", "    return train_losses, val_losses\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Model evaluation\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Evaluaci\u00f3n del modelo\n", "def evaluate_model(model, test_loader):\n", "    model.eval()\n", "    y_true, y_pred = [], []\n", "    with torch.no_grad():\n", "        for images, labels in test_loader:\n", "            images, labels = images.to(device), labels.to(device)\n", "            outputs = model(images)\n", "            _, preds = torch.max(outputs, 1)\n", "            y_true.extend(labels.cpu().numpy())\n", "            y_pred.extend(preds.cpu().numpy())\n", "    print(classification_report(y_true, y_pred, target_names=class_names))\n", "    conf_matrix = confusion_matrix(y_true, y_pred)\n", "    plt.figure(figsize=(10, 8))\n", "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n", "    plt.ylabel('Etiqueta verdadera')\n", "    plt.xlabel('Etiqueta predicha')\n", "    plt.title('Matriz de confusi\u00f3n')\n", "    plt.show()\n"]}, {"cell_type": "code", "metadata": {}, "source": ["# Probar diferentes arquitecturas\n", "for model_name in ['resnet18', 'vgg16', 'efficientnet_b0']:\n", "    print(f'\\nEntrenando con la arquitectura {model_name}')\n", "    model = create_model(model_name)\n", "    train_model(model, train_loader, val_loader, epochs, lr)\n", "    print(f'\\nEvaluando el modelo {model_name}')\n", "    evaluate_model(model, test_loader)\n"]}]}